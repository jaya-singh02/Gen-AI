{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a19459-9b38-4755-8df2-bcef0e4ee6f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 10) (1348363131.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    prompt = f\"Check the grammar of the following text.\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated f-string literal (detected at line 10)\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def correct_grammar(text):\n",
    "    llm = ChatGroq(\n",
    "        model=\"gemma2-9b-it\",\n",
    "        temperature=0,\n",
    "        groq_api_key=\"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\"  # Replace with your actual API key\n",
    "    )\n",
    "    \n",
    "    prompt = f\"Check the grammar of the following text. \n",
    "    If it's correct, return it as is. \n",
    "    If it has grammar mistakes, correct them without \n",
    "    changing the meaning or adding extra words. \n",
    "    Also, list the incorrect words and provide feedback \n",
    "    on what went wrong.\\nText: {text}\"\n",
    "    \n",
    "    response = llm.invoke(prompt)  # Get AIMessage object\n",
    "    corrected_text = response.content  # Extract actual text\n",
    "    \n",
    "    if corrected_text.strip() == text.strip():\n",
    "        print(\"\\nSentence is already correct:\", text)\n",
    "    else:\n",
    "        print(\"\\nCorrected Text:\", corrected_text)\n",
    "        \n",
    "        # The response from the model should ideally contain the list of incorrect words and feedback\n",
    "        if \"incorrect words\" in corrected_text.lower():\n",
    "            # Extract incorrect words and explanations (assuming response structure includes it)\n",
    "            incorrect_words_feedback = extract_incorrect_words(corrected_text) \n",
    "            print(\"\\nIncorrect Words and Feedback:\", incorrect_words_feedback)\n",
    "\n",
    "def extract_incorrect_words(response_text):\n",
    "    # Implement logic to parse incorrect words and their explanations from the response\n",
    "    # This will depend on how the LLM outputs feedback, here assuming a simplified approach\n",
    "    incorrect_words = []\n",
    "    lines = response_text.splitlines()\n",
    "    for line in lines:\n",
    "        if \"incorrect\" in line.lower():\n",
    "            incorrect_words.append(line.strip())\n",
    "    return incorrect_words\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = input(\"Enter a sentence to check grammar: \")\n",
    "    correct_grammar(input_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
